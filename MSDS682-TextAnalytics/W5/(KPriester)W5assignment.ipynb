{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Assignment\n",
    "\n",
    "## Summary:\n",
    "\n",
    "In this week's assignment, I used the glob library to load in 16 files - each containing tweets from various news media sources, with the full dataset totaling to over 65,000 tweets. The `cleanCorpus` function was modified so that the `spaCy` library would do most of the text processing functions that are usually done with the `NLTK` library. In the beginning of the function, only apostrophes are removed from the tweets so that contractions aren't separated when tokenized (e.g. people's -> people and 's) and can be properly lemmatized later. After converting the text to a `spaCy` object, the function checks if the lemmatization of a word is a pronoun (changed from the actual word to `-PRON-`) and if so, keep the normal text of the word so that it can get properly checked in the stopwords section. If the word is not a pronoun, then it keeps its lemmatized form. Next, the words are checked to see if they are stopwords, retweets, URLs, or usernames (**note**: `spaCy` does tweet tokenization, so URLs and usernames stay together with their prefix (`http` and `@`, respectively). Finally, the rest of the punctuation and double spaces (caused by removing dashes between whitespaces) are removed before adding the cleaned tweet to the `clean_document` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from glob import iglob\n",
    "\n",
    "en_stopwords = stopwords.words('english')  \n",
    "stopwords = set(en_stopwords)\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an empty dataframe\n",
    "#empty dataframe will hold all the tweets from all the files\n",
    "healthtweet_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 846: expected 3 fields, saw 4\\nSkipping line 904: expected 3 fields, saw 4\\nSkipping line 914: expected 3 fields, saw 4\\nSkipping line 1264: expected 3 fields, saw 4\\nSkipping line 1269: expected 3 fields, saw 4\\nSkipping line 1293: expected 3 fields, saw 4\\nSkipping line 1348: expected 3 fields, saw 4\\nSkipping line 1430: expected 3 fields, saw 4\\nSkipping line 1486: expected 3 fields, saw 4\\nSkipping line 1710: expected 3 fields, saw 4\\nSkipping line 2699: expected 3 fields, saw 4\\nSkipping line 2728: expected 3 fields, saw 4\\nSkipping line 3000: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 1422: expected 3 fields, saw 4\\nSkipping line 1461: expected 3 fields, saw 4\\nSkipping line 1468: expected 3 fields, saw 4\\nSkipping line 1507: expected 3 fields, saw 4\\nSkipping line 1547: expected 3 fields, saw 4\\nSkipping line 1728: expected 3 fields, saw 4\\nSkipping line 1738: expected 3 fields, saw 4\\nSkipping line 1742: expected 3 fields, saw 4\\nSkipping line 1847: expected 3 fields, saw 5\\nSkipping line 2082: expected 3 fields, saw 4\\nSkipping line 2125: expected 3 fields, saw 4\\nSkipping line 3860: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 638: expected 3 fields, saw 4\\nSkipping line 966: expected 3 fields, saw 4\\nSkipping line 1890: expected 3 fields, saw 4\\nSkipping line 2601: expected 3 fields, saw 4\\nSkipping line 2602: expected 3 fields, saw 4\\nSkipping line 2606: expected 3 fields, saw 4\\nSkipping line 2609: expected 3 fields, saw 4\\nSkipping line 2611: expected 3 fields, saw 4\\nSkipping line 2627: expected 3 fields, saw 4\\nSkipping line 2642: expected 3 fields, saw 4\\nSkipping line 2647: expected 3 fields, saw 4\\nSkipping line 2656: expected 3 fields, saw 4\\nSkipping line 2662: expected 3 fields, saw 4\\nSkipping line 2663: expected 3 fields, saw 4\\nSkipping line 2664: expected 3 fields, saw 4\\nSkipping line 2665: expected 3 fields, saw 4\\nSkipping line 2667: expected 3 fields, saw 4\\nSkipping line 2670: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 4015: expected 3 fields, saw 4\\nSkipping line 6118: expected 3 fields, saw 4\\nSkipping line 6354: expected 3 fields, saw 4\\nSkipping line 6429: expected 3 fields, saw 4\\nSkipping line 6528: expected 3 fields, saw 4\\nSkipping line 6930: expected 3 fields, saw 4\\nSkipping line 6944: expected 3 fields, saw 4\\nSkipping line 6948: expected 3 fields, saw 4\\nSkipping line 6949: expected 3 fields, saw 4\\nSkipping line 6951: expected 3 fields, saw 5\\nSkipping line 6954: expected 3 fields, saw 4\\nSkipping line 6956: expected 3 fields, saw 4\\nSkipping line 6965: expected 3 fields, saw 4\\nSkipping line 6984: expected 3 fields, saw 4\\nSkipping line 6988: expected 3 fields, saw 4\\nSkipping line 7020: expected 3 fields, saw 4\\nSkipping line 7049: expected 3 fields, saw 4\\nSkipping line 7058: expected 3 fields, saw 4\\nSkipping line 7118: expected 3 fields, saw 4\\nSkipping line 7126: expected 3 fields, saw 4\\nSkipping line 7131: expected 3 fields, saw 4\\nSkipping line 7135: expected 3 fields, saw 4\\nSkipping line 7163: expected 3 fields, saw 4\\nSkipping line 7177: expected 3 fields, saw 4\\nSkipping line 7223: expected 3 fields, saw 4\\nSkipping line 7240: expected 3 fields, saw 4\\nSkipping line 7241: expected 3 fields, saw 4\\nSkipping line 7277: expected 3 fields, saw 4\\nSkipping line 7289: expected 3 fields, saw 4\\nSkipping line 7293: expected 3 fields, saw 4\\nSkipping line 7320: expected 3 fields, saw 4\\nSkipping line 7327: expected 3 fields, saw 4\\nSkipping line 7334: expected 3 fields, saw 4\\nSkipping line 7338: expected 3 fields, saw 4\\nSkipping line 7345: expected 3 fields, saw 4\\nSkipping line 7374: expected 3 fields, saw 4\\nSkipping line 7380: expected 3 fields, saw 4\\nSkipping line 7383: expected 3 fields, saw 4\\nSkipping line 7392: expected 3 fields, saw 4\\nSkipping line 7409: expected 3 fields, saw 4\\nSkipping line 7412: expected 3 fields, saw 4\\nSkipping line 7418: expected 3 fields, saw 4\\nSkipping line 7422: expected 3 fields, saw 4\\nSkipping line 7427: expected 3 fields, saw 4\\nSkipping line 7439: expected 3 fields, saw 4\\nSkipping line 7446: expected 3 fields, saw 4\\nSkipping line 7447: expected 3 fields, saw 4\\nSkipping line 7458: expected 3 fields, saw 4\\nSkipping line 7484: expected 3 fields, saw 4\\nSkipping line 7498: expected 3 fields, saw 4\\nSkipping line 7502: expected 3 fields, saw 4\\nSkipping line 7505: expected 3 fields, saw 4\\nSkipping line 7512: expected 3 fields, saw 4\\nSkipping line 7537: expected 3 fields, saw 4\\nSkipping line 7538: expected 3 fields, saw 4\\nSkipping line 7544: expected 3 fields, saw 4\\nSkipping line 7552: expected 3 fields, saw 4\\nSkipping line 7572: expected 3 fields, saw 4\\nSkipping line 7573: expected 3 fields, saw 4\\nSkipping line 7588: expected 3 fields, saw 4\\nSkipping line 7647: expected 3 fields, saw 4\\nSkipping line 7664: expected 3 fields, saw 4\\nSkipping line 7670: expected 3 fields, saw 4\\nSkipping line 7691: expected 3 fields, saw 4\\nSkipping line 7715: expected 3 fields, saw 4\\nSkipping line 7746: expected 3 fields, saw 4\\nSkipping line 7755: expected 3 fields, saw 4\\nSkipping line 7769: expected 3 fields, saw 4\\nSkipping line 7775: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 523: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 71: expected 3 fields, saw 4\\nSkipping line 88: expected 3 fields, saw 4\\nSkipping line 130: expected 3 fields, saw 4\\nSkipping line 145: expected 3 fields, saw 4\\nSkipping line 257: expected 3 fields, saw 4\\nSkipping line 272: expected 3 fields, saw 4\\nSkipping line 325: expected 3 fields, saw 4\\nSkipping line 401: expected 3 fields, saw 4\\nSkipping line 412: expected 3 fields, saw 4\\nSkipping line 426: expected 3 fields, saw 4\\nSkipping line 507: expected 3 fields, saw 4\\nSkipping line 813: expected 3 fields, saw 4\\nSkipping line 1319: expected 3 fields, saw 4\\nSkipping line 1576: expected 3 fields, saw 4\\nSkipping line 1592: expected 3 fields, saw 4\\nSkipping line 1686: expected 3 fields, saw 4\\nSkipping line 1929: expected 3 fields, saw 4\\nSkipping line 2019: expected 3 fields, saw 4\\nSkipping line 2359: expected 3 fields, saw 4\\nSkipping line 2438: expected 3 fields, saw 4\\nSkipping line 2679: expected 3 fields, saw 4\\nSkipping line 2680: expected 3 fields, saw 4\\nSkipping line 2681: expected 3 fields, saw 4\\nSkipping line 3098: expected 3 fields, saw 4\\nSkipping line 3380: expected 3 fields, saw 4\\nSkipping line 3723: expected 3 fields, saw 4\\nSkipping line 4013: expected 3 fields, saw 4\\nSkipping line 4024: expected 3 fields, saw 4\\nSkipping line 4026: expected 3 fields, saw 4\\nSkipping line 4181: expected 3 fields, saw 4\\nSkipping line 4283: expected 3 fields, saw 4\\nSkipping line 4305: expected 3 fields, saw 4\\nSkipping line 4403: expected 3 fields, saw 4\\nSkipping line 4443: expected 3 fields, saw 4\\nSkipping line 4475: expected 3 fields, saw 4\\nSkipping line 4576: expected 3 fields, saw 4\\nSkipping line 4636: expected 3 fields, saw 4\\nSkipping line 4661: expected 3 fields, saw 4\\nSkipping line 4739: expected 3 fields, saw 4\\nSkipping line 4780: expected 3 fields, saw 4\\nSkipping line 4782: expected 3 fields, saw 4\\nSkipping line 4783: expected 3 fields, saw 4\\nSkipping line 4798: expected 3 fields, saw 4\\nSkipping line 4805: expected 3 fields, saw 4\\nSkipping line 4816: expected 3 fields, saw 4\\nSkipping line 4905: expected 3 fields, saw 4\\nSkipping line 4922: expected 3 fields, saw 4\\nSkipping line 4954: expected 3 fields, saw 4\\nSkipping line 4955: expected 3 fields, saw 4\\nSkipping line 4956: expected 3 fields, saw 4\\nSkipping line 4989: expected 3 fields, saw 4\\nSkipping line 5020: expected 3 fields, saw 4\\nSkipping line 5021: expected 3 fields, saw 4\\nSkipping line 5036: expected 3 fields, saw 4\\nSkipping line 5051: expected 3 fields, saw 4\\nSkipping line 5076: expected 3 fields, saw 4\\nSkipping line 5096: expected 3 fields, saw 4\\nSkipping line 5164: expected 3 fields, saw 4\\nSkipping line 5165: expected 3 fields, saw 4\\nSkipping line 5175: expected 3 fields, saw 4\\nSkipping line 5178: expected 3 fields, saw 4\\nSkipping line 5192: expected 3 fields, saw 4\\nSkipping line 5261: expected 3 fields, saw 4\\nSkipping line 5322: expected 3 fields, saw 4\\nSkipping line 5329: expected 3 fields, saw 4\\nSkipping line 5376: expected 3 fields, saw 4\\nSkipping line 5380: expected 3 fields, saw 4\\nSkipping line 5383: expected 3 fields, saw 4\\nSkipping line 5400: expected 3 fields, saw 4\\nSkipping line 5414: expected 3 fields, saw 4\\nSkipping line 5448: expected 3 fields, saw 4\\nSkipping line 5465: expected 3 fields, saw 4\\nSkipping line 5477: expected 3 fields, saw 4\\nSkipping line 5495: expected 3 fields, saw 4\\nSkipping line 5515: expected 3 fields, saw 4\\nSkipping line 5521: expected 3 fields, saw 4\\nSkipping line 5558: expected 3 fields, saw 4\\nSkipping line 5587: expected 3 fields, saw 4\\nSkipping line 5624: expected 3 fields, saw 4\\nSkipping line 5637: expected 3 fields, saw 4\\nSkipping line 5686: expected 3 fields, saw 4\\nSkipping line 5710: expected 3 fields, saw 4\\nSkipping line 5767: expected 3 fields, saw 4\\nSkipping line 5791: expected 3 fields, saw 4\\nSkipping line 5799: expected 3 fields, saw 4\\nSkipping line 5845: expected 3 fields, saw 4\\nSkipping line 5861: expected 3 fields, saw 4\\nSkipping line 5868: expected 3 fields, saw 4\\nSkipping line 5901: expected 3 fields, saw 4\\nSkipping line 5923: expected 3 fields, saw 4\\nSkipping line 5925: expected 3 fields, saw 4\\nSkipping line 5928: expected 3 fields, saw 4\\nSkipping line 5946: expected 3 fields, saw 4\\nSkipping line 5957: expected 3 fields, saw 4\\nSkipping line 5958: expected 3 fields, saw 4\\nSkipping line 5997: expected 3 fields, saw 4\\nSkipping line 6017: expected 3 fields, saw 4\\nSkipping line 6037: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "#load in each text file from the Health Tweets folder\n",
    "for file in iglob('Health-Tweets/*.txt'):\n",
    "    \n",
    "    #each file read in as dataframe\n",
    "    df = pd.read_csv(file,\n",
    "                     sep='|',\n",
    "                     header=None,\n",
    "                     error_bad_lines=False,\n",
    "                     encoding='latin-1')\n",
    "    \n",
    "    #single file dataframe is attached to larger dataframe\n",
    "    healthtweet_df = healthtweet_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62817"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many rows (tweets)\n",
    "len(healthtweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column headers to the dataframe\n",
    "healthtweet_df.columns = ['ID', 'timestamp', 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>585978391360221184</td>\n",
       "      <td>Thu Apr 09 01:31:50 +0000 2015</td>\n",
       "      <td>Breast cancer risk test devised http://bbc.in/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585947808772960257</td>\n",
       "      <td>Wed Apr 08 23:30:18 +0000 2015</td>\n",
       "      <td>GP workload harming care - BMA poll http://bbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585947807816650752</td>\n",
       "      <td>Wed Apr 08 23:30:18 +0000 2015</td>\n",
       "      <td>Short people's 'heart risk greater' http://bbc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585866060991078401</td>\n",
       "      <td>Wed Apr 08 18:05:28 +0000 2015</td>\n",
       "      <td>New approach against HIV 'promising' http://bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585794106170839041</td>\n",
       "      <td>Wed Apr 08 13:19:33 +0000 2015</td>\n",
       "      <td>Coalition 'undermined NHS' - doctors http://bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>585733482413891584</td>\n",
       "      <td>Wed Apr 08 09:18:39 +0000 2015</td>\n",
       "      <td>Review of case against NHS manager http://bbc....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>585733481608646657</td>\n",
       "      <td>Wed Apr 08 09:18:39 +0000 2015</td>\n",
       "      <td>VIDEO: 'All day is empty, what am I going to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>585701601131765761</td>\n",
       "      <td>Wed Apr 08 07:11:58 +0000 2015</td>\n",
       "      <td>VIDEO: 'Overhaul needed' for end-of-life care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>585620828110397440</td>\n",
       "      <td>Wed Apr 08 01:51:00 +0000 2015</td>\n",
       "      <td>Care for dying 'needs overhaul' http://bbc.in/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>585437294120677376</td>\n",
       "      <td>Tue Apr 07 13:41:42 +0000 2015</td>\n",
       "      <td>VIDEO: NHS: Labour and Tory key policies http:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                       timestamp  \\\n",
       "0  585978391360221184  Thu Apr 09 01:31:50 +0000 2015   \n",
       "1  585947808772960257  Wed Apr 08 23:30:18 +0000 2015   \n",
       "2  585947807816650752  Wed Apr 08 23:30:18 +0000 2015   \n",
       "3  585866060991078401  Wed Apr 08 18:05:28 +0000 2015   \n",
       "4  585794106170839041  Wed Apr 08 13:19:33 +0000 2015   \n",
       "5  585733482413891584  Wed Apr 08 09:18:39 +0000 2015   \n",
       "6  585733481608646657  Wed Apr 08 09:18:39 +0000 2015   \n",
       "7  585701601131765761  Wed Apr 08 07:11:58 +0000 2015   \n",
       "8  585620828110397440  Wed Apr 08 01:51:00 +0000 2015   \n",
       "9  585437294120677376  Tue Apr 07 13:41:42 +0000 2015   \n",
       "\n",
       "                                               tweet  \n",
       "0  Breast cancer risk test devised http://bbc.in/...  \n",
       "1  GP workload harming care - BMA poll http://bbc...  \n",
       "2  Short people's 'heart risk greater' http://bbc...  \n",
       "3  New approach against HIV 'promising' http://bb...  \n",
       "4  Coalition 'undermined NHS' - doctors http://bb...  \n",
       "5  Review of case against NHS manager http://bbc....  \n",
       "6  VIDEO: 'All day is empty, what am I going to d...  \n",
       "7  VIDEO: 'Overhaul needed' for end-of-life care ...  \n",
       "8  Care for dying 'needs overhaul' http://bbc.in/...  \n",
       "9  VIDEO: NHS: Labour and Tory key policies http:...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify dataframe contents\n",
    "healthtweet_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"tweet\" column into a list\n",
    "healthtweet_ls = healthtweet_df['tweet'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will return a list (clean_document) that contains each document (tweet) as a string after making the text lowercase, removing aspotrophes, \n",
    "converting into a spaCy object (tokenizing), lemmatizing the words, removing stopwords and Twitter-related extras, rejoining as a string,\n",
    "then removing all remaining punctuation, numbers, and double white spaces. The final string product is then added to the 'clean_document' list.\n",
    "\"\"\"\n",
    "\n",
    "#function to lowercase, remove punctuation/digits, tokenize (split into words), and remove stopwords\n",
    "def cleanCorpus(corpus):\n",
    "    \n",
    "    clean_document = []\n",
    "    \n",
    "    for doc in corpus:\n",
    "        \"\"\"\n",
    "        stopwords (list) has split contractions in it\n",
    "        \"\"\"\n",
    "        #apostrophes to look for\n",
    "        #so words like \"people's\" don't become \"people\" and \"'s\"\n",
    "        table = str.maketrans({key: None for key in \"'\" + \"‘\" + \"’\"})\n",
    "        \n",
    "        #string w/o apostrophe                    \n",
    "        no_apos_str = doc.translate(table).lower()\n",
    "        \n",
    "        #make tweet into a spaCy object\n",
    "        nlpdoc = nlp(no_apos_str)\n",
    "        \n",
    "        #holds words that are lemmatized, with tweet stuff (http, URLs, and @user) removed\n",
    "        clean_lemmals = []\n",
    "        \n",
    "        \n",
    "        for token in nlpdoc:\n",
    "            \n",
    "            #check to see if lemma is \"-PRON-\"\n",
    "            #needs to stay in normal text form to get checked as a stopword\n",
    "            if token.lemma_ == '-PRON-':\n",
    "                token_lem = token.text\n",
    "            else:\n",
    "            #lemmatize the word\n",
    "                token_lem = token.lemma_\n",
    "            \n",
    "            #check for stopwords, retweets (\"RT\"), URLs, or users (@username)\n",
    "            if (token_lem in stopwords) or (token_lem == \"rt\") or (token_lem.startswith((\"http\",'@'))): pass\n",
    "            \n",
    "            else: clean_lemmals.append(token_lem)\n",
    "                \n",
    "        \n",
    "        #join list of cleaned words together into one string\n",
    "        clean_str = \" \".join(clean_lemmals)  \n",
    "\n",
    "        #remove rest of punctuation and digits\n",
    "        #didn't do earlier b/c I didn't want @ removed\n",
    "        table = str.maketrans({key: None for key in string.punctuation + string.digits + \"¦\"})\n",
    "        nopunct_digits = clean_str.translate(table)\n",
    "        rmv_ws = nopunct_digits.replace(\"  \", \" \")\n",
    "    \n",
    "        #add string of the cleaned tweet to this list\n",
    "        clean_document.append(rmv_ws)\n",
    "        \n",
    "\n",
    "    #confirmation that all documents are finished with text cleaning process\n",
    "    print(\"Corpus is clean.\")\n",
    "    \n",
    "    #returned output is a list with each document item from corpus as a string\n",
    "    return clean_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is clean.\n"
     ]
    }
   ],
   "source": [
    "#run the cleanCorpus function\n",
    "cleanhealth_ls = cleanCorpus(healthtweet_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "After running the `cleanCorpus` function on the dataset, I used the `TfidfVectorizer()` function to convert the cleaned tweet data into a matrix, where each row is a tweet and the columns are the terms from all the tweets. The total number of terms in the matrix is 22,254 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save TF-IDF vectorizer into a variable\n",
    "tfidfvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a TF-IDF matrix from the text data\n",
    "twt_mtx = tfidfvec.fit_transform(cleanhealth_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62817, 22259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensions of the matrix\n",
    "twt_mtx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "\n",
    "Using the K-Means function with 10 clusters initialized and randomized data, I fit the data into the model and used the `predict` function to produce the cluster assignment for each tweet. Then using the `silhouette_score` function in combination with the TF-IDF matrix and cluster prediction assignments, I calculated the silhouette score for the 10 cluster K-Means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the KMeans algorithm into a variable\n",
    "#initialized with 10 clusters and randomize the data\n",
    "kmeans10 = KMeans(n_clusters=10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=10, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model with the data\n",
    "kmeans10.fit(twt_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict which clusters the tweets belong to\n",
    "cluster_pred = kmeans10.predict(twt_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify first 5 data points' cluster assignments\n",
    "cluster_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10 clusters, the average silhouette score is: 0.007501837023813563\n"
     ]
    }
   ],
   "source": [
    "#get the silhouette score for the model    \n",
    "sil_avg = silhouette_score(twt_mtx, cluster_pred)\n",
    "\n",
    "print(f\"For 10 clusters, the average silhouette score is: {sil_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Terms\n",
    "\n",
    "First, I (separatedly) gathered the tweets that were assigned to Cluster 0 & 3, and then used the `FreqDist` and `.most_common()` functions to get the top 10 words in those clusters. After verifying the results, I ran a loop to get the top 5 words for each cluster in the K-Means model assignment output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['breast cancer risk test devise', 'gp workload harm care bma poll',\n",
       "       'short people heart risk great', 'coalition undermine nhs doctor',\n",
       "       'review case nhs manager'], dtype='<U9509')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the tweets that were assigned to Cluster 0\n",
    "#verify the first 5 tweets in the cluster\n",
    "c0twt = np.array(cleanhealth_ls)[cluster_pred == 0]\n",
    "c0twt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cancer', 1529),\n",
       " ('us', 1468),\n",
       " ('drug', 1324),\n",
       " ('nhs', 1227),\n",
       " ('food', 1204),\n",
       " ('help', 1048),\n",
       " ('patient', 1024),\n",
       " ('good', 990),\n",
       " ('doctor', 978),\n",
       " ('hospital', 914)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a frequency distribution of the tweets in Cluster 0\n",
    "#get top 10 words in Cluster 0\n",
    "wordcount = FreqDist(word_tokenize(' '.join(c0twt)))\n",
    "wordcount.most_common(10)\n",
    "#us is U.S. (periods were removed after stopword cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['treat nhs whistleblower well mps', ' needle well one',\n",
       "       'well sex  dementia care call',\n",
       "       'well hospital food may become law',\n",
       "       'british ebola patient pretty well'], dtype='<U9509')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the tweets that were assigned to Cluster 3\n",
    "#verify the first 5 tweets in the cluster\n",
    "c3twt = np.array(cleanhealth_ls)[cluster_pred == 3]\n",
    "c3twt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('well', 2006),\n",
       " ('may', 130),\n",
       " ('doctor', 119),\n",
       " ('health', 113),\n",
       " ('cancer', 113),\n",
       " ('ask', 112),\n",
       " ('exercise', 84),\n",
       " ('get', 83),\n",
       " ('patient', 74),\n",
       " ('risk', 74)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a frequency distribution of the tweets in Cluster 3\n",
    "#get top 10 words in Cluster 3\n",
    "wordcount3 = FreqDist(word_tokenize(' '.join(c3twt)))\n",
    "wordcount3.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 5 words in Cluster 0:\n",
      "cancer\n",
      "us\n",
      "drug\n",
      "nhs\n",
      "food\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 1:\n",
      "new\n",
      "old\n",
      "age\n",
      "blog\n",
      "york\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 2:\n",
      "health\n",
      "law\n",
      "care\n",
      "insurance\n",
      "mental\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 3:\n",
      "well\n",
      "may\n",
      "doctor\n",
      "health\n",
      "cancer\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 4:\n",
      "get\n",
      "health\n",
      "way\n",
      "help\n",
      "new\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 5:\n",
      "make\n",
      "weight\n",
      "lose\n",
      "loss\n",
      "help\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 6:\n",
      "say\n",
      "study\n",
      "ebola\n",
      "health\n",
      "us\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 7:\n",
      "may\n",
      "help\n",
      "risk\n",
      "study\n",
      "cancer\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 8:\n",
      "study\n",
      "find\n",
      "cancer\n",
      "risk\n",
      "drug\n",
      "\n",
      "\n",
      "The Top 5 words in Cluster 9:\n",
      "ebola\n",
      "us\n",
      "patient\n",
      "outbreak\n",
      "africa\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print the top 5 words for each cluster from the KMeans model (10 clusters)\n",
    "\n",
    "k10cluster_labels = list(set(cluster_pred))\n",
    "\n",
    "for cluster_label in k10cluster_labels:\n",
    "    \n",
    "    cluster_tweets = np.array(cleanhealth_ls)[cluster_pred == cluster_label]\n",
    "    \n",
    "    top5 = FreqDist(word_tokenize(' '.join(cluster_tweets))).most_common(5)\n",
    "    \n",
    "    print(f\"The Top 5 words in Cluster {cluster_label}:\")\n",
    "    \n",
    "    for word in top5:\n",
    "        print(word[0])\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Clusters\n",
    "\n",
    "Based on the silhouette score for the 10 cluster K-Means model, I looped through a list of numbers to represent 15-20 clusters and produce a silhouette score for each. Then using that same list of numbers, I also calculated the WSS score and plotted it as an Elbow Curve to see the trend of possible optimal clusters for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of numbers 15-20\n",
    "#will use to evaluate the model with 15-20 clusters\n",
    "cluster_num = list(range(15,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 15 clusters, the average silhouette score is: 0.008654045571451968\n",
      "For 16 clusters, the average silhouette score is: 0.008768678766837495\n",
      "For 17 clusters, the average silhouette score is: 0.009404388516385625\n",
      "For 18 clusters, the average silhouette score is: 0.010466856753471334\n",
      "For 19 clusters, the average silhouette score is: 0.009476304442323698\n",
      "For 20 clusters, the average silhouette score is: 0.010888852443090374\n"
     ]
    }
   ],
   "source": [
    "#silhouette score of 15-20 clusters\n",
    "\n",
    "for n in cluster_num:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n, random_state=10)\n",
    "    \n",
    "    cluster_pred = kmeans.fit_predict(twt_mtx)\n",
    "    \n",
    "    sil_avg = silhouette_score(twt_mtx, cluster_pred)\n",
    "    \n",
    "    print(f\"For {n} clusters, the average silhouette score is: {sil_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate WSS for 15-20 clusters\n",
    "scores = []\n",
    "\n",
    "for n in cluster_num:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n, random_state=10)\n",
    "    \n",
    "    score = kmeans.fit(twt_mtx).score(twt_mtx)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Elbow Curve for 15-20 clusters\n",
    "plt.plot(cluster_num,scores)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Elbow Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-60818.588940819485,\n",
       " -60741.66522618543,\n",
       " -60637.4822595683,\n",
       " -60478.31723401694,\n",
       " -60528.59707546889,\n",
       " -60380.56102542885]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WSS scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "About half of the time for this assignment was spent modifiying the `cleanCorpus` function because stopwords were bypassing the checkpoint (in an earlier version of the function, words were checked as stopwords first then lemmatized but some words didn't become stopwords until after the lemmatization). The other majority was used running the model and seeing in the Top 10 list that some stopwords had slipped through. The reason why running the model took more time is because the matrix was computationally expensive and although I attempted to use the `ProcessPoolExecutor()` function, it seems that on my Windows 10 machine I have to add extra functions in a separate script, so I decided to take the time to wait for my computer to finish running the `cleanCorpus` and `.fit()` functions on the data each time I made an adjustment (an estimated 9-11 minutes for each function).\n",
    "\n",
    "However, once I received an acceptable output from the model, calculating the scores was much easier. The silhouette score for the 10 cluster model was not that great (~0.008) and in a test version of the silhouette score of lower numbered clusters (2-7 clusters), I found the scores getting worse and determined that higher scores might trend towards the optimal number of clusters for this dataset. After running the silhouette score for 15-20 clusters, the results showed that by 20 clusters (~0.011 score) the score seemed to be improving, and therefore more clusters would most likely be best for this model. So I also tested this with WSS scores and by looking at the plot for the same number of clusters (15-20), there is an upward trend that supports my earlier findings for more clusters being suited for this dataset. \n",
    "\n",
    "The high number of clusters being optimal for this data is probably due to the number of significant news events that are contained in the dataset. Looking at the common words in Cluster 0, the topic seems to be about the FDA discovering a new drug related to breast cancer. Cluster 3 has words related to a new law involving insurance and mental health. Cluster 8 discusses a case of ebola in a patient in the United States, while Cluster 9 has words regarding the new healthcare related to the National Health Service (in the United Kingdom). With news media outlets reporting big stories on a frequent basis, the number of unique events would most likely surpass 20 topics and would need more clusters to accurately bin them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "Karami, A. (2018, February 19). Retrieved from https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Selecting the number of clusters with silhouette analysis on KMeans clustering. Retrieved from https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "K-Means Clustering: Analysing City of London Traffic. Retrieved from https://www.michael-grogan.com/k-means-clustering-python-sklearn/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
